---
id: strings-l2-unicode-normalization-nfc-nfd
title: "Unicode Normalization (NFC/NFD)"
topic: strings
level: 2
lesson: 2.3
prereqs:
  - strings-l2-utf16-code-units-vs-code-points
  - strings-l2-grapheme-clusters-and-emoji
  - strings-l1-basic-search-compare
outcomes:
  - "Explain **canonical equivalence** and the four normalization forms: **NFC, NFD, NFKC, NFKD**"
  - Use `String.prototype.normalize(form?)` safely and predict when output changes
  - Choose a **house style** (usually **NFC**) for storage, equality, and indexing
  - Implement `canonicalEquals`, `normalizeSafe`, and **accent folding** (`accentFold`) for search
  - Build a simple **normalized search index** and understand when to normalize vs just fold
tags: ["strings","unicode","normalization","NFC","NFD","NFKC","NFKD","accent-folding","search"]
est_minutes: 45
concepts_introduced:
  - strings.normalize.nfc
  - strings.normalize.accent_folding
concepts_reused:
  - strings.unicode.codepoints
  - strings.unicode.graphemes
crosslinks:
  - { to: strings-l3-case-folding-and-simple-normalization, why: "Case folding combines with normalization for search pipelines" }
  - { to: strings-l4-search-highlight-and-snippets, why: "Use normalized forms before slicing for highlights" }
  - { to: strings-l5-accent-insensitive-search-pipelines, why: "Locale-aware pipelines build on NFC + accent folding" }
checks:
  - type: quiz
    id: strings-l2-unicode-normalization-quiz
  - type: unit
    entry: canonicalEquals.ts
    tests: canonicalEquals.test.ts
  - type: unit
    entry: normalizeSafe.ts
    tests: normalizeSafe.test.ts
  - type: unit
    entry: isNormalized.ts
    tests: isNormalized.test.ts
  - type: unit
    entry: accentFold.ts
    tests: accentFold.test.ts
  - type: unit
    entry: normalizedIndex.ts
    tests: normalizedIndex.test.ts
---

## Why this matters

Two visually identical strings can have **different binary contents**. Example: `"Ã©"` can be a single code point (`U+00E9`) or two (`"e" + U+0301`). If you compare naÃ¯vely, youâ€™ll miss matches, create duplicate keys, or break search highlights. **Normalization** gives you a consistent representationâ€”usually **NFC**â€”so equality and indexing behave.

---

## Canonical equivalence & the four forms

- **NFC** (Normalization Form C): *compose* where possible. `"e\u0301"` â†’ `"\u00E9"`.
- **NFD** (Normalization Form D): *decompose* into base + combining marks. `"\u00E9"` â†’ `"e\u0301"`.
- **NFKC / NFKD**: like NFC/NFD but with **compatibility** mappings (e.g., â€œâ‘ â€ â†’ â€œ1â€). Good for search/ID canonicalization; **may lose formatting**.

Rule of thumb:
- **Storage & equality:** NFC.
- **Search (accent-insensitive):** normalize (NFD) â†’ **remove combining marks** â†’ (optionally) recompose to NFC.
- **Aggressive canonicalization:** NFKC/NFKD, but be careful with semantics.

---

## `String.prototype.normalize(form?)`

```ts
"e\u0301".normalize("NFC");  // "\u00E9"  (Ã© composed)
"\u00E9".normalize("NFD");   // "e\u0301" (decomposed)
"â‘ ".normalize("NFKC");       // "1"
````

* Default form is `"NFC"`.
* Normalization is **idempotent**: `s.normalize("NFC").normalize("NFC") === s.normalize("NFC")`.

> Performance: Normalizing every string blindly is wasteful. Normalize:
>
> * at **boundaries** (input, storage),
> * when **comparing**/keying,
> * when **building indices**.

---

## Practical policies (pick one and document it)

1. **House NFC**

   * On ingest: `s = s.normalize("NFC")`.
   * For equality & keys: compare NFC strings.
   * For search: NFC â†’ **accent fold** (below) â†’ case fold.

2. **Accent-insensitive search**

   * Index & queries: `NFD â†’ strip combining marks â†’ toLowerCase/toLocaleLowerCase â†’ NFC (optional)`.

---

## Utilities

### 1) Canonical equality (NFC)

```ts
export function canonicalEquals(a: string, b: string): boolean {
  // Normalize *both* sides to NFC and compare
  return a.normalize("NFC") === b.normalize("NFC");
}
```

### 2) Safe normalization (guard & fast-path)

```ts
export function normalizeSafe(s: unknown, form: "NFC"|"NFD"|"NFKC"|"NFKD" = "NFC"): string {
  if (typeof s !== "string") return String(s ?? "");
  // Fast path: if already normalized, return as-is (cheap check)
  // NOTE: This check still walks the string; keep for large pipelines only if measured.
  return s === s.normalize(form) ? s : s.normalize(form);
}
```

### 3) Check if a string is already normalized

```ts
export function isNormalized(s: string, form: "NFC"|"NFD"|"NFKC"|"NFKD" = "NFC"): boolean {
  return s === s.normalize(form);
}
```

### 4) Accent folding (diacritics removal)

Policy: **NFD â†’ remove `\p{M}` marks â†’ NFC**. This keeps base letters, drops accents.

```ts
// Requires ES2018 Unicode property escapes (the /u flag)
const COMBINING_MARKS = /\p{M}+/gu;

export function accentFold(s: string): string {
  // 1) Normalize to NFD (decompose accents)
  // 2) Remove all combining marks
  // 3) Recompose to NFC (optional but tidy)
  return s.normalize("NFD").replace(COMBINING_MARKS, "").normalize("NFC");
}

// Examples:
accentFold("SÃ£o TomÃ©");     // "Sao Tome"
accentFold("e\u0301");      // "e"
accentFold("ðŸ™â“ªâ‘ ");         // "101" only if you use NFKC elsewhere (this fold does not)
```

> **Note:** Accent folding does **not** equal compatibility folding. If you need to reduce circled/roman numerals etc., consider **NFKC** before/after folding and test carefully.

### 5) Normalized search index (toy)

```ts
export type NormalizedIndex = {
  raw: string[];        // original items
  keys: string[];       // normalized keys (NFC + accent/case fold)
};

export function buildIndex(items: string[], opts = { accentInsensitive: true, caseInsensitive: true }) : NormalizedIndex {
  const keys = items.map(s => {
    let k = s.normalize("NFC");
    if (opts.accentInsensitive) k = accentFold(k);
    if (opts.caseInsensitive) k = k.toLowerCase(); // or toLocaleLowerCase(locale)
    return k;
  });
  return { raw: items.slice(), keys };
}

export function searchIndex(idx: NormalizedIndex, query: string): number[] {
  let q = query.normalize("NFC");
  q = accentFold(q).toLowerCase();
  const out: number[] = [];
  for (let i = 0; i < idx.keys.length; i++) if (idx.keys[i].includes(q)) out.push(i);
  return out;
}
```

---

## Pitfalls

* **Mixing forms**: concatenating normalized + unnormalized pieces can reintroduce decomposed sequences. Normalize **after** concatenation if needed.
* **Over-normalizing**: doing `s.normalize()` inside tight loops unnecessarily. Prefer normalizing **once** at boundaries or indexing time.
* **NFKC/NFKD surprises**: they change semantics (e.g., half-width katakana, circled numbers). Donâ€™t use for equality unless explicitly desired.
* **Regex & marks**: make sure to use the **`u` flag** with `\p{M}`; otherwise the property class isnâ€™t recognized.

---

## Exercises

### 1) `canonicalEquals(a, b)` â€” NFC equality

Normalize both inputs to **NFC** and compare.

**Starter â€” `canonicalEquals.ts`**

```ts
export function canonicalEquals(a: string, b: string): boolean {
  return a.normalize("NFC") === b.normalize("NFC");
}
```

---

### 2) `normalizeSafe(s, form?)` â€” guard + fast-path

Convert non-strings to strings, then normalize with the given form (default NFC). Use the idempotent fast path.

**Starter â€” `normalizeSafe.ts`**

```ts
export function normalizeSafe(s: unknown, form: "NFC"|"NFD"|"NFKC"|"NFKD" = "NFC"): string {
  if (typeof s !== "string") return String(s ?? "");
  return s === s.normalize(form) ? s : s.normalize(form);
}
```

---

### 3) `isNormalized(s, form?)` â€” check form quickly

Return `true` if `s` is already in the desired form.

**Starter â€” `isNormalized.ts`**

```ts
export function isNormalized(s: string, form: "NFC"|"NFD"|"NFKC"|"NFKD" = "NFC"): boolean {
  return s === s.normalize(form);
}
```

---

### 4) `accentFold(s)` â€” remove diacritics via NFD

Strip Unicode combining marks using `\p{M}` and recompose to NFC.

**Starter â€” `accentFold.ts`**

```ts
const COMBINING_MARKS = /\p{M}+/gu;

export function accentFold(s: string): string {
  return s.normalize("NFD").replace(COMBINING_MARKS, "").normalize("NFC");
}
```

---

### 5) `normalizedIndex.ts` â€” tiny NFC + fold index

Export `buildIndex(items)` and `searchIndex(idx, query)` as above (NFC â†’ accentFold â†’ lower-case).

**Starter â€” `normalizedIndex.ts`**

```ts
import { accentFold } from "./accentFold";

export type NormalizedIndex = { raw: string[]; keys: string[] };

export function buildIndex(items: string[]): NormalizedIndex {
  const keys = items.map(s => accentFold(s.normalize("NFC")).toLowerCase());
  return { raw: items.slice(), keys };
}

export function searchIndex(idx: NormalizedIndex, query: string): number[] {
  const q = accentFold(query.normalize("NFC")).toLowerCase();
  const hits: number[] = [];
  for (let i = 0; i < idx.keys.length; i++) if (idx.keys[i].includes(q)) hits.push(i);
  return hits;
}
```

---

## Quiz (checks)

1. `"Ã©" === "e\u0301"` is usually:
   A) **`false`** âœ…
   B) `true`
   C) Throws
   D) Locale-dependent

2. The best default **storage** form is:
   A) NFD
   B) **NFC** âœ…
   C) NFKC
   D) Raw input with no normalization

3. **Accent folding** typically means:
   A) `toUpperCase()`
   B) **Decompose (NFD), remove combining marks, recompose (NFC)** âœ…
   C) Use NFKC only
   D) Remove all non-ASCII characters

4. `String.prototype.normalize()` default is:
   A) NFD
   B) NFKC
   C) **NFC** âœ…
   D) No change unless you pass a form

5. Compatibility forms (**NFKC/NFKD**) are risky for equality because:
   A) Theyâ€™re slower
   B) **They can change character semantics (e.g., â€œâ‘ â€ â†’ â€œ1â€)** âœ…
   C) They donâ€™t handle accents
   D) Theyâ€™re browser-only

---

## Takeaways

* Normalize to **NFC** for storage and equality; use **NFD + mark removal** for accent-insensitive search.
* `normalize()` is idempotent; apply it **at boundaries** and when building indices, not on every operation.
* Be cautious with **NFKC/NFKD**â€”great for canonicalization, but they can change meaning.
* Next up: weâ€™ll combine normalization with case folding and regex tools to build robust text pipelines.

---

## Whatâ€™s next

Move to **Strings L2 â€” Safe Length & Slicing (Code Points & Graphemes)** to apply normalization-aware counting and build truncation/slicing utilities that donâ€™t split user-visible characters.
