---
id: arrays-l4-anagrams-pipeline
title: "Anagrams Pipeline (split ‚Üí sort ‚Üí join vs Frequency Map)"
topic: arrays
level: 4
lesson: 4.3
prereqs:
  - arrays-l2-sort-and-compare
  - arrays-l2-map-filter-reduce-flat-flatMap
  - strings-l2-basics
outcomes:
  - "Implement anagram checks using **two strategies**: `split ‚Üí sort ‚Üí join` and **frequency maps**"
  - Choose the right strategy based on input size, constraints, and normalization needs
  - Normalize strings safely (case, whitespace, punctuation) and understand Unicode caveats
  - Group a list of words into anagram classes efficiently
  - Analyze complexities and memory trade-offs for each approach
tags: ["arrays","strings","composition","anagram","frequency","normalization","map"]
est_minutes: 40
checks:
  - type: quiz
    id: arrays-l4-anagrams-quiz
  - type: unit
    entry: isAnagram_sort.ts
    tests: isAnagram_sort.test.ts
  - type: unit
    entry: isAnagram_freq.ts
    tests: isAnagram_freq.test.ts
  - type: unit
    entry: groupAnagrams.ts
    tests: groupAnagrams.test.ts
  - type: unit
    entry: canonicalize.ts
    tests: canonicalize.test.ts
---

## Why this matters

Anagrams are a perfect playground for **method composition** and **data-structure choice**:
- The classic **pipeline** uses `split ‚Üí sort ‚Üí join`.
- The scalable alternative uses a **frequency map** (`Map<char, count>`).
You‚Äôll practice composing Array methods with Strings and understand when each approach wins.

---

## Problem definition

Two strings `a` and `b` are **anagrams** if, after normalization (same alphabet + case rules), they contain the **same multiset of characters**.

**Normalization decisions** (be explicit!):
- Lowercase? Remove spaces? Strip punctuation/diacritics?  
- Unicode handling (see caveats below).

We‚Äôll start with simple ASCII-ish rules, then note how to extend.

---

## Strategy 1 ‚Äî `split ‚Üí sort ‚Üí join` (simple, O(n log n))

**Idea:** Sort the characters of each normalized string and compare.

```ts
function isAnagramSort(a: string, b: string): boolean {
  const A = canonicalize(a);
  const B = canonicalize(b);
  if (A.length !== B.length) return false;
  return A.split("").sort().join("") === B.split("").sort().join("");
}
````

**Pros**

* Very short, easy to reason about.
* Great for short strings or quick checks.

**Cons**

* Sorting is **O(n log n)**.
* Naive `split("")` splits into **UTF-16 code units**, which can split surrogate pairs (see Unicode notes).
* Repeated for many words becomes costly.

---

## Strategy 2 ‚Äî Frequency map (linear, O(n))

**Idea:** Count characters in `a`, subtract counts using `b`. All zeros ‚Üí anagram.

```ts
function isAnagramFreq(a: string, b: string): boolean {
  const A = canonicalize(a);
  const B = canonicalize(b);
  if (A.length !== B.length) return false;

  const freq = new Map<string, number>();
  for (const ch of A) freq.set(ch, (freq.get(ch) ?? 0) + 1);
  for (const ch of B) {
    const next = (freq.get(ch) ?? 0) - 1;
    if (next < 0) return false;
    freq.set(ch, next);
  }
  // Optional final check: all zero (not needed if length check passed + negatives blocked)
  return true;
}
```

**Pros**

* **O(n)** time, **O(u)** space (u = unique chars).
* Easy to extend to multi-language alphabets.

**Cons**

* More code than the pipeline.
* Requires careful normalization to ensure same character space.

---

## Grouping an entire list (anagram classes)

We can **canonicalize each word to a key** and group equal keys.

### Using sorted-key (simple)

```ts
function keySorted(word: string): string {
  const W = canonicalize(word);
  return W.split("").sort().join(""); // canonical signature
}

export function groupAnagrams(words: string[]): string[][] {
  const buckets = new Map<string, string[]>();
  for (const w of words) {
    const k = keySorted(w);
    (buckets.get(k) ?? buckets.set(k, []).get(k)!).push(w.trim());
  }
  return [...buckets.values()];
}
```

### Using frequency-key (handles very long strings better)

Encode counts into a compact key, e.g. for a fixed alphabet or by joining `char:count` pairs.

---

## Normalization (`canonicalize`)

Start with pragmatic defaults and document them:

```ts
// Default: trim, lowercase, remove spaces and basic punctuation, Unicode NFC normalize
export function canonicalize(s: string): string {
  return s
    .normalize("NFC")
    .toLowerCase()
    .replace(/[\s\p{P}\p{S}]+/gu, ""); // remove spaces, punctuation, symbols
}
```

* `normalize("NFC")` helps treat composed and decomposed forms as equal (e.g., ‚Äú√©‚Äù vs ‚ÄúeÃÅ‚Äù).
* The regex uses Unicode property escapes (`\p{‚Ä¶}`) ‚Üí requires modern JS.
* Adjust the removal set to your product needs (maybe keep apostrophes, etc.).

---

## Unicode caveats (important)

* `split("")` splits into **code units**, not **grapheme clusters**. Some characters (emoji, accents) can be multi-unit.
* A safer iteration is `for (const ch of str)` or `[...str]`, which iterates **code points**. Still, grapheme clusters (like ‚Äúüá∫üá∏‚Äù) are multi-code-point; matching human-perceived characters may require `Intl.Segmenter` (advanced).
* If you operate on mostly ASCII or basic Latin letters after normalization, the simple approach is OK.

> For our MVP lessons, prefer `for‚Ä¶of` iteration and `normalize("NFC")`.

---

## Complexity & trade-offs

| Task                   | Sorted pipeline                                  | Frequency map                                          |
| ---------------------- | ------------------------------------------------ | ------------------------------------------------------ |
| `isAnagram(a,b)`       | **O(n log n)** time, O(n) space                  | **O(n)** time, O(u) space                              |
| `groupAnagrams(words)` | Per word sort O(n log n); overall O(Œ£ n·µ¢ log n·µ¢) | Build frequency key O(n) per word; key build more code |

Rule of thumb:

* **Short strings / quick checks** ‚Üí sorted pipeline is fine.
* **Long strings / many words** ‚Üí frequency or precomputed keys.

---

## Walkthrough: compare strategies on sample inputs

```ts
const A = "Dormitory";
const B = "Dirty room!!";
// With canonicalize ‚Üí "dormitory" vs "dirtyroom" ‚Üí true by either strategy

const C = "r√©sum√©";
const D = "s√©rum√©";
// NFC + lowercase + removing punctuation still treats them as equal characters.
```

---

## Exercises

### 1) `isAnagram_sort(a, b)` ‚Äî pipeline method

**Starter ‚Äî `isAnagram_sort.ts`**

```ts
import { canonicalize } from "./canonicalize";

export function isAnagram_sort(a: string, b: string): boolean {
  // Use canonicalize + split ‚Üí sort ‚Üí join
  return false;
}
```

---

### 2) `isAnagram_freq(a, b)` ‚Äî frequency map method

**Starter ‚Äî `isAnagram_freq.ts`**

```ts
import { canonicalize } from "./canonicalize";

export function isAnagram_freq(a: string, b: string): boolean {
  // Use Map counts in O(n)
  return false;
}
```

---

### 3) `groupAnagrams(words)` ‚Äî group by canonical key

**Starter ‚Äî `groupAnagrams.ts`**

```ts
import { canonicalize } from "./canonicalize";

export function groupAnagrams(words: string[]): string[][] {
  // Choose sorted-key or frequency-key; preserve input order within each bucket
  return [];
}
```

**Requirements**

* Words that reduce to the same canonical form land in the same bucket.
* Preserve the order of first appearance within each bucket.
* Empty/whitespace-only strings should be ignored or grouped under empty key (document your choice in code comments; tests expect ‚Äúignore empties‚Äù).

---

### 4) `canonicalize(s)` ‚Äî configurable normalization

**Starter ‚Äî `canonicalize.ts`**

```ts
export type CanonOpts = {
  lowercase?: boolean;         // default true
  stripSpaces?: boolean;       // default true
  stripPunct?: boolean;        // default true
  form?: "NFC" | "NFD" | "NFKC" | "NFKD"; // default "NFC"
};

export function canonicalize(s: string, opts: CanonOpts = {}): string {
  // Implement defaults; use Unicode-aware regex with /u
  return s;
}
```

**Tests cover**

* Case folding
* NFC normalization (‚Äú√©‚Äù variants)
* Stripping spaces/punctuation
* Leaving punctuation when `stripPunct:false`

---

## Quiz (checks)

1. Complexity of `split ‚Üí sort ‚Üí join` for strings of length `n` is:
   A) O(n)
   B) **O(n log n)** ‚úÖ
   C) O(log n)
   D) O(n¬≤)

2. Frequency map approach runs in:
   A) **O(n)** time, O(u) space ‚úÖ
   B) O(n log n) time, O(1) space
   C) O(u log u) time, O(n) space
   D) O(1) time, O(n) space

3. `split("")` on Unicode text may:
   A) Respect grapheme clusters
   B) Return code points
   C) **Split surrogate pairs (code units)** ‚úÖ
   D) Throw on emoji

4. To treat ‚Äú√©‚Äù and ‚ÄúeÃÅ‚Äù as equal, you should:
   A) Lowercase only
   B) Use `localeCompare`
   C) **Use `normalize("NFC")` (or similar) before comparison** ‚úÖ
   D) Use `toUpperCase`

5. For grouping many long words into anagram classes, prefer:
   A) Sorted key approach always
   B) **Frequency-based key or precomputed canonical keys** ‚úÖ
   C) Brute-force pairwise comparisons
   D) JSON stringify

---

## Takeaways

* The classic **sorted pipeline** is compact and great for small/quick tasks.
* The **frequency map** scales to longer strings and bulk grouping with **O(n)** time.
* **Normalization** choices define equality‚Äîbe explicit and Unicode-aware.
* Iterating with `for‚Ä¶of` handles code points better than `split("")`, but true grapheme handling may require `Intl.Segmenter`.

---

## What‚Äôs next

Head to **Arrays L4 ‚Äî Sliding Window Katas** to apply Arrays + Numbers in real problems (max-sum window, minimal subarray ‚â• S, and more) with O(n) scans.
