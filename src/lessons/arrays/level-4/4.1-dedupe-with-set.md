---
id: arrays-l4-dedupe-with-set
title: "Dedupe with Set (and Map for keys)"
topic: arrays
level: 4
lesson: 4.1
prereqs:
  - arrays-l1-overview
  - arrays-l2-searching-and-testing
  - set-l1-basics
outcomes:
  - Remove duplicates from arrays of primitives using `Set` while preserving order
  - Dedupe arrays of objects by a **key function** using `Set`/`Map`
  - Choose first-win vs last-win semantics and implement both efficiently
  - Understand SameValueZero equality (`NaN` equals `NaN`, `+0` equals `-0`) in Sets
  - "Analyze time/space: O(n) expected time, O(u) space (u = unique keys)"
tags: ["arrays","set","map","dedupe","uniqueness","keys","SameValueZero"]
est_minutes: 35
checks:
  - type: quiz
    id: arrays-l4-dedupe-quiz
  - type: unit
    entry: uniquePrimitives.ts
    tests: uniquePrimitives.test.ts
  - type: unit
    entry: uniqueBy.ts
    tests: uniqueBy.test.ts
  - type: unit
    entry: uniqueNormalizedStrings.ts
    tests: uniqueNormalizedStrings.test.ts
  - type: unit
    entry: uniqueLastBy.ts
    tests: uniqueLastBy.test.ts
---

## Why this matters

“Keep only unique items” shows up *everywhere*: user IDs, emails, tags, product SKUs, etc. With **Set** you get clean, O(n) dedupe for primitives; with **Map/Set + key extractor**, you can do the same for objects—while keeping control over **which duplicate wins** and preserving order.

---

## Mental model

- `Set` tracks **membership** by **SameValueZero** equality:
  - `NaN` equals `NaN`
  - `+0` equals `-0`
- Iteration order of `Set` is **insertion order**.
- For **objects**, Set compares by **identity** (reference), so two distinct `{id:1}` are different. Use a **key function** to derive a primitive key (string/number/boolean) and track those in a `Set`/`Map`.

**Complexity:** Single left→right scan; each lookup/insertion is expected O(1) → **O(n)** time, **O(u)** space.

---

## Quick wins (primitives)

```ts
// Keep first occurrence of each value, stable order:
const unique = <T>(xs: T[]) => [...new Set(xs)];

unique([3, 3, 2, NaN, NaN, -0, 0]); // [3, 2, NaN, -0]
````

> Because Sets keep insertion order, the result preserves the **first** time each value was seen.

---

## Dedupe by **key** (objects)

Use a `keyFn` to map each item to a primitive key; skip items whose key was seen.

```ts
type User = { id: string; email: string; name: string };

function uniqueBy<T, K extends (string|number|boolean)>(
  xs: T[],
  keyFn: (x: T) => K
): T[] {
  const seen = new Set<K>();
  const out: T[] = [];
  for (const x of xs) {
    const k = keyFn(x);
    if (!seen.has(k)) { seen.add(k); out.push(x); } // first-win
  }
  return out;
}

// Examples:
uniqueBy(users, u => u.id);
uniqueBy(users, u => u.email.toLowerCase().trim()); // normalize for equality
```

**Why `Set` and not `Map`?** For first-win, a `Set` of keys is enough. If you need to **pick the last** or return a **Map of key→item**, use a `Map`.

---

## First-win vs last-win

* **First-win** (keep earliest occurrence): scan **left→right**, push first time you see a key (as above).
* **Last-win** (keep latest occurrence): scan **right→left**, push first time you see a key, then **reverse** at the end (to restore original order among kept items).

```ts
function uniqueLastBy<T, K extends (string|number|boolean)>(
  xs: T[],
  keyFn: (x: T) => K
): T[] {
  const seen = new Set<K>();
  const out: T[] = [];
  for (let i = xs.length - 1; i >= 0; i--) {
    const x = xs[i], k = keyFn(x);
    if (!seen.has(k)) { seen.add(k); out.push(x); }
  }
  return out.reverse();
}
```

---

## Common pitfalls

* **Objects in Set**: `{id:1}` and `{id:1}` are different unless you key them (e.g., `id`).
* **JSON stringify as key**: fragile—property order, large strings, Dates/Maps/Sets/functions don’t serialize well. Prefer explicit, small keys.
* **Normalization**: emails/usernames often need `trim().toLowerCase()`. Define equality **up front**.
* **Memory**: Dedupe keeps a `Set` of size `u`—fine for typical lists; chunk or stream for huge data.

---

## Walkthrough: casing/whitespace tolerant emails

Goal: keep one email per person, ignoring case and extra spaces, but **preserve the first canonical form** we saw.

```ts
function uniqueNormalizedEmails(emails: string[]): string[] {
  const seen = new Set<string>();   // normalized
  const out: string[] = [];         // original forms
  for (const e of emails) {
    const norm = e.trim().toLowerCase();
    if (!seen.has(norm)) { seen.add(norm); out.push(e.trim()); }
  }
  return out;
}
```

---

## Exercises

### 1) `uniquePrimitives(xs)` — primitives only (first-win)

Return a new array with duplicates removed, preserving first occurrence order. Handle `NaN`, `+0/-0` per Set semantics.

**Starter — `uniquePrimitives.ts`**

```ts
export function uniquePrimitives<T>(xs: T[]): T[] {
  // Use Set + spread or manual scan
  return [];
}
```

---

### 2) `uniqueBy(xs, keyFn)` — generic key-based dedupe (first-win)

Keep the **first** item for each key. Keys must be string/number/boolean.

**Starter — `uniqueBy.ts`**

```ts
export function uniqueBy<T, K extends string | number | boolean>(
  xs: T[],
  keyFn: (x: T) => K
): T[] {
  return [];
}
```

**Tests cover**

* Objects with duplicate `id`
* Case-insensitive emails
* Already-unique arrays (return shallow-equal contents)

---

### 3) `uniqueNormalizedStrings(xs)` — normalize then dedupe

Given `string[]`, dedupe by `normalize(x)` but **return the trimmed original** form of the first occurrence.

**Starter — `uniqueNormalizedStrings.ts`**

```ts
export function uniqueNormalizedStrings(
  xs: string[],
  normalize: (s: string) => string = s => s.trim().toLowerCase()
): string[] {
  return [];
}
```

---

### 4) `uniqueLastBy(xs, keyFn)` — last-win semantics

Return one item per key, where **later** items override earlier ones; preserve the relative order of kept items as they appeared originally.

**Starter — `uniqueLastBy.ts`**

```ts
export function uniqueLastBy<T, K extends string | number | boolean>(
  xs: T[],
  keyFn: (x: T) => K
): T[] {
  return [];
}
```

**Hint:** Scan right→left using a `Set`, collect, then reverse.

---

## Quiz (checks)

1. Set equality uses:
   A) Strict equality (`===`)
   B) SameValue
   C) **SameValueZero** ✅ (so `NaN` equals `NaN`, `+0` equals `-0`)
   D) JSON string equality

2. `[...new Set([1,1,2,NaN,NaN,-0,0])]` is:
   A) `[1,2,NaN,0]`
   B) `[1,2,NaN,-0]` ✅
   C) `[1,1,2,NaN,NaN,-0,0]`
   D) `[1,2]`

3. Why doesn’t `new Set([{id:1},{id:1}]).size` equal 1?
   A) Set is broken
   B) Objects are compared by **reference**, not structure ✅
   C) JSON stringify is required by Set
   D) SameValueZero treats objects as equal

4. To implement **last-win** dedupe efficiently you should:
   A) Scan left→right and `splice` duplicates
   B) Scan right→left with a `Set`, then reverse the result ✅
   C) Sort by key then use `Set`
   D) Use `filter` + `indexOf`

5. What’s the expected time/space for `uniqueBy` on `n` elements with `u` unique keys?
   A) O(n log n) time, O(1) space
   B) **O(n)** time, **O(u)** space ✅
   C) O(u) time, O(n) space
   D) O(1) time, O(n) space

---

## Takeaways

* For primitives, `new Set(xs)` + spread gives you fast, stable **first-win** dedupe.
* For objects, **key extraction** is the right tool—use `Set`/`Map` keyed by a normalized primitive.
* Pick and implement your **winning rule** (first vs last) explicitly.
* Know Set’s equality (SameValueZero) and iteration order (insertion), and budget O(u) memory.

---

## What’s next

Continue to **Arrays L4 — GroupBy & Frequency** to turn arrays into buckets and counts using `Map`/objects, powering histograms, reports, and aggregations.
